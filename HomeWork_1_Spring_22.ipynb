{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "210bb436",
      "metadata": {
        "id": "210bb436"
      },
      "source": [
        "# Homework 1: Applied Machine Learning - Linear | Logisitc | SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e27c90a6",
      "metadata": {
        "id": "e27c90a6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import inv\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b6a7879a",
      "metadata": {
        "id": "b6a7879a"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "def fxn():\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    fxn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dec72e60",
      "metadata": {
        "id": "dec72e60"
      },
      "outputs": [],
      "source": [
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdb2d5a",
      "metadata": {
        "id": "5bdb2d5a"
      },
      "source": [
        "#**Part 1: Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86aea694",
      "metadata": {
        "id": "86aea694"
      },
      "source": [
        "In part 1, we will use **two datasets** to train and evaluate our linear regression model.\n",
        "\n",
        "The first dataset will be a synthetic dataset sampled from the following equations:\n",
        "   \n",
        "**ùúñ ‚àº Normal(0,3**)\n",
        "\n",
        "**z = 3ùë• + 10y + 10 + ùúñ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4b1775f9",
      "metadata": {
        "id": "4b1775f9"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "epsilon = np.random.normal(0, 3, 100)\n",
        "x = np.linspace(0, 10, 100) \n",
        "y = np.linspace(0, 5, 100)\n",
        "z = 3 * x + 10 * y + 10 + epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f9c1a48",
      "metadata": {
        "id": "9f9c1a48"
      },
      "source": [
        "To apply linear regression, we need to first check if the assumptions of linear regression are not violated.\n",
        "\n",
        "Assumptions of Linear Regression:\n",
        "\n",
        "- Linearity: $y$ is a linear (technically affine) function of $x$.\n",
        "- Independence: the $x$'s are independently drawn, and not dependent on each other.\n",
        "- Homoscedasticity: the $\\epsilon$'s, and thus the $y$'s, have constant variance.\n",
        "- Normality: the $\\epsilon$'s are drawn from a Normal distribution (i.e. Normally-distributed errors)\n",
        "\n",
        "These properties, as well as the simplicity of this dataset, will make it a good test case to check if our linear regression model is working properly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2be3e924",
      "metadata": {
        "id": "2be3e924"
      },
      "source": [
        "**1.1. Plot z vs x and z vs y in the synthetic dataset as scatter plots. Label your axes and make sure your y-axis starts from 0. Do the independent and dependent features have linear relationship?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5145cad",
      "metadata": {
        "id": "c5145cad"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94433e8e",
      "metadata": {
        "id": "94433e8e"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dbb473b",
      "metadata": {
        "id": "0dbb473b"
      },
      "source": [
        "**1.2. Are the independent variables correlated? Use pearson correlation to verify? What would be the problem if linear regression is applied to correlated features?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445ba11c",
      "metadata": {
        "id": "445ba11c"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d57cd121",
      "metadata": {
        "id": "d57cd121"
      },
      "source": [
        "**The second dataset we will be using is an auto MPG dataset. This dataset contains various characteristics for around 8128 cars. We will use linear regression to predict the selling_price label**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_mpg_df = pd.read_csv('Car details v3.csv')\n",
        "# Dropping Torque column, there is information in this column but it will take some preprocessing.\n",
        "# The idea of the exercise is to familarize yourself with the basics of Linear regression.\n",
        "auto_mpg_df = auto_mpg_df.drop(['torque'], axis = 1)"
      ],
      "metadata": {
        "id": "d6lnQQunWxCx"
      },
      "id": "d6lnQQunWxCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01532cf",
      "metadata": {
        "id": "d01532cf",
        "outputId": "ea9cb509-bcc8-46bb-db9d-b1e8f71def48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>year</th>\n",
              "      <th>selling_price</th>\n",
              "      <th>km_driven</th>\n",
              "      <th>fuel</th>\n",
              "      <th>seller_type</th>\n",
              "      <th>transmission</th>\n",
              "      <th>owner</th>\n",
              "      <th>mileage</th>\n",
              "      <th>engine</th>\n",
              "      <th>max_power</th>\n",
              "      <th>seats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Maruti Swift Dzire VDI</td>\n",
              "      <td>2014</td>\n",
              "      <td>450000</td>\n",
              "      <td>145500</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.4 kmpl</td>\n",
              "      <td>1248 CC</td>\n",
              "      <td>74 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
              "      <td>2014</td>\n",
              "      <td>370000</td>\n",
              "      <td>120000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>Second Owner</td>\n",
              "      <td>21.14 kmpl</td>\n",
              "      <td>1498 CC</td>\n",
              "      <td>103.52 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Honda City 2017-2020 EXi</td>\n",
              "      <td>2006</td>\n",
              "      <td>158000</td>\n",
              "      <td>140000</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>Third Owner</td>\n",
              "      <td>17.7 kmpl</td>\n",
              "      <td>1497 CC</td>\n",
              "      <td>78 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hyundai i20 Sportz Diesel</td>\n",
              "      <td>2010</td>\n",
              "      <td>225000</td>\n",
              "      <td>127000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.0 kmpl</td>\n",
              "      <td>1396 CC</td>\n",
              "      <td>90 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Maruti Swift VXI BSIII</td>\n",
              "      <td>2007</td>\n",
              "      <td>130000</td>\n",
              "      <td>120000</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>16.1 kmpl</td>\n",
              "      <td>1298 CC</td>\n",
              "      <td>88.2 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8123</th>\n",
              "      <td>Hyundai i20 Magna</td>\n",
              "      <td>2013</td>\n",
              "      <td>320000</td>\n",
              "      <td>110000</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>18.5 kmpl</td>\n",
              "      <td>1197 CC</td>\n",
              "      <td>82.85 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8124</th>\n",
              "      <td>Hyundai Verna CRDi SX</td>\n",
              "      <td>2007</td>\n",
              "      <td>135000</td>\n",
              "      <td>119000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>Fourth &amp; Above Owner</td>\n",
              "      <td>16.8 kmpl</td>\n",
              "      <td>1493 CC</td>\n",
              "      <td>110 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8125</th>\n",
              "      <td>Maruti Swift Dzire ZDi</td>\n",
              "      <td>2009</td>\n",
              "      <td>382000</td>\n",
              "      <td>120000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>19.3 kmpl</td>\n",
              "      <td>1248 CC</td>\n",
              "      <td>73.9 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8126</th>\n",
              "      <td>Tata Indigo CR4</td>\n",
              "      <td>2013</td>\n",
              "      <td>290000</td>\n",
              "      <td>25000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.57 kmpl</td>\n",
              "      <td>1396 CC</td>\n",
              "      <td>70 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8127</th>\n",
              "      <td>Tata Indigo CR4</td>\n",
              "      <td>2013</td>\n",
              "      <td>290000</td>\n",
              "      <td>25000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.57 kmpl</td>\n",
              "      <td>1396 CC</td>\n",
              "      <td>70 bhp</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8128 rows √ó 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              name  year  selling_price  km_driven    fuel  \\\n",
              "0           Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
              "1     Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
              "2         Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
              "3        Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
              "4           Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
              "...                            ...   ...            ...        ...     ...   \n",
              "8123             Hyundai i20 Magna  2013         320000     110000  Petrol   \n",
              "8124         Hyundai Verna CRDi SX  2007         135000     119000  Diesel   \n",
              "8125        Maruti Swift Dzire ZDi  2009         382000     120000  Diesel   \n",
              "8126               Tata Indigo CR4  2013         290000      25000  Diesel   \n",
              "8127               Tata Indigo CR4  2013         290000      25000  Diesel   \n",
              "\n",
              "     seller_type transmission                 owner     mileage   engine  \\\n",
              "0     Individual       Manual           First Owner   23.4 kmpl  1248 CC   \n",
              "1     Individual       Manual          Second Owner  21.14 kmpl  1498 CC   \n",
              "2     Individual       Manual           Third Owner   17.7 kmpl  1497 CC   \n",
              "3     Individual       Manual           First Owner   23.0 kmpl  1396 CC   \n",
              "4     Individual       Manual           First Owner   16.1 kmpl  1298 CC   \n",
              "...          ...          ...                   ...         ...      ...   \n",
              "8123  Individual       Manual           First Owner   18.5 kmpl  1197 CC   \n",
              "8124  Individual       Manual  Fourth & Above Owner   16.8 kmpl  1493 CC   \n",
              "8125  Individual       Manual           First Owner   19.3 kmpl  1248 CC   \n",
              "8126  Individual       Manual           First Owner  23.57 kmpl  1396 CC   \n",
              "8127  Individual       Manual           First Owner  23.57 kmpl  1396 CC   \n",
              "\n",
              "       max_power  seats  \n",
              "0         74 bhp    5.0  \n",
              "1     103.52 bhp    5.0  \n",
              "2         78 bhp    5.0  \n",
              "3         90 bhp    5.0  \n",
              "4       88.2 bhp    5.0  \n",
              "...          ...    ...  \n",
              "8123   82.85 bhp    5.0  \n",
              "8124     110 bhp    5.0  \n",
              "8125    73.9 bhp    5.0  \n",
              "8126      70 bhp    5.0  \n",
              "8127      70 bhp    5.0  \n",
              "\n",
              "[8128 rows x 12 columns]"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auto_mpg_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcccde60",
      "metadata": {
        "id": "bcccde60"
      },
      "source": [
        "**1.3. Missing Value analysis - Auto mpg dataset.**\n",
        "\n",
        "**Are there any missing values in the dataset? If so, what can be done about it? Jusify your approach.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7136afc9",
      "metadata": {
        "id": "7136afc9"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d809bb8e",
      "metadata": {
        "id": "d809bb8e"
      },
      "source": [
        "**1.4. The features engine, max_power and mileage have units in the dataset. In the real world if we have such datasets, we generally remove the units from each feature. After doing so, convert the datatype of these columns to float. For example: 1248 CC engine is 1248, 23.4 kmpl is 23.4 and so on.**\n",
        "\n",
        "**Hint: Check for distinct units in each of these features. A feature might have multiple units as well. Also, a feature could have no value but have unit. For example 'CC' without any value. Remove such rows.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b76d44",
      "metadata": {
        "id": "21b76d44"
      },
      "outputs": [],
      "source": [
        "### Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862d73f9",
      "metadata": {
        "id": "862d73f9"
      },
      "outputs": [],
      "source": [
        "auto_mpg_X = auto_mpg_df.drop(columns=['selling_price'])\n",
        "auto_mpg_y = auto_mpg_df['selling_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e881aff2",
      "metadata": {
        "id": "e881aff2"
      },
      "source": [
        "**1.5. Plot the distribution of the label (selling_price) using a histogram. Make multiple plots with different binwidths. Make sure to label your axes while plotting.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f96e30",
      "metadata": {
        "id": "a0f96e30"
      },
      "outputs": [],
      "source": [
        "### Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b87f7d8",
      "metadata": {
        "id": "5b87f7d8"
      },
      "source": [
        "**1.6. Plot the relationships between the label (Selling Price) and the continuous features (Mileage, km driven, engine, max power) using a small multiple of scatter plots. \n",
        "Make sure to label the axes. Do you see something interesting about the distributions of these features.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b62169",
      "metadata": {
        "id": "c3b62169"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84ffa354",
      "metadata": {
        "id": "84ffa354"
      },
      "source": [
        "**1.7. Plot the relationships between the label (Selling Price) and the discrete features (fuel type, Seller type, transmission) using a small multiple of box plots. Make sure to label the axes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16812f56",
      "metadata": {
        "id": "16812f56"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28eaf41d",
      "metadata": {
        "id": "28eaf41d"
      },
      "source": [
        "**1.8. From the visualizations above, do you think linear regression is a good model for this problem? Why and/or why not?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c93674",
      "metadata": {
        "id": "50c93674"
      },
      "outputs": [],
      "source": [
        "### Your answer here\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7fb6c1",
      "metadata": {
        "id": "1c7fb6c1"
      },
      "outputs": [],
      "source": [
        "auto_mpg_X['year'] =  2020 - auto_mpg_X['year']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdee656",
      "metadata": {
        "id": "4fdee656",
        "outputId": "c91123e2-48c1-4046-d283-3e54926a9a8a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>km_driven</th>\n",
              "      <th>fuel</th>\n",
              "      <th>seller_type</th>\n",
              "      <th>transmission</th>\n",
              "      <th>owner</th>\n",
              "      <th>mileage</th>\n",
              "      <th>engine</th>\n",
              "      <th>max_power</th>\n",
              "      <th>seats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>145500</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.40</td>\n",
              "      <td>1248</td>\n",
              "      <td>74.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>120000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>Second Owner</td>\n",
              "      <td>21.14</td>\n",
              "      <td>1498</td>\n",
              "      <td>103.52</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>140000</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>Third Owner</td>\n",
              "      <td>17.70</td>\n",
              "      <td>1497</td>\n",
              "      <td>78.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>127000</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>23.00</td>\n",
              "      <td>1396</td>\n",
              "      <td>90.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>120000</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Individual</td>\n",
              "      <td>Manual</td>\n",
              "      <td>First Owner</td>\n",
              "      <td>16.10</td>\n",
              "      <td>1298</td>\n",
              "      <td>88.20</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  km_driven    fuel seller_type transmission         owner  mileage  \\\n",
              "0     6     145500  Diesel  Individual       Manual   First Owner    23.40   \n",
              "1     6     120000  Diesel  Individual       Manual  Second Owner    21.14   \n",
              "2    14     140000  Petrol  Individual       Manual   Third Owner    17.70   \n",
              "3    10     127000  Diesel  Individual       Manual   First Owner    23.00   \n",
              "4    13     120000  Petrol  Individual       Manual   First Owner    16.10   \n",
              "\n",
              "   engine  max_power  seats  \n",
              "0    1248      74.00    5.0  \n",
              "1    1498     103.52    5.0  \n",
              "2    1497      78.00    5.0  \n",
              "3    1396      90.00    5.0  \n",
              "4    1298      88.20    5.0  "
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dropping the car name as it is irrelevant.\n",
        "auto_mpg_X.drop(['name'],axis = 1,inplace=True)\n",
        "\n",
        "#check out the dataset with new changes\n",
        "auto_mpg_X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ebca87",
      "metadata": {
        "id": "71ebca87"
      },
      "source": [
        "**Data Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6980d1e4",
      "metadata": {
        "id": "6980d1e4"
      },
      "source": [
        "**1.9.\n",
        "Before we can fit a linear regression model, there are several pre-processing steps we should apply to the datasets:**\n",
        "1. Encode categorial features appropriately.\n",
        "2. Split the dataset into training (60%), validation (20%), and test (20%) sets.\n",
        "3. Standardize the columns in the feature matrices X_train, X_val, and X_test to have zero mean and unit variance. To avoid information leakage, learn the standardization parameters (mean, variance) from X_train, and apply it to X_train, X_val, and X_test.\n",
        "4. Add a column of ones to the feature matrices X_train, X_val, and X_test. This is a common trick so that we can learn a coefficient for the bias term of a linear model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8711d6a7",
      "metadata": {
        "id": "8711d6a7"
      },
      "outputs": [],
      "source": [
        "# 1. No categorical features in the synthetic dataset (skip this step)\n",
        "\n",
        "# 2. Split the dataset into training (60%), validation (20%), and test (20%) sets\n",
        "\n",
        "# 3. Standardize the columns in the feature matrices\n",
        "\n",
        "# 4. Add a column of ones to the feature matrices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950f6e97",
      "metadata": {
        "id": "950f6e97"
      },
      "source": [
        "**At the end of this pre-processing, you should have the following vectors and matrices:**\n",
        "\n",
        "**- Auto MPG dataset: auto_mpg_X_train, auto_mpg_X_val, auto_mpg_X_test, auto_mpg_y_train, auto_mpg_y_val, auto_mpg_y_test**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3b7ca8",
      "metadata": {
        "id": "1e3b7ca8"
      },
      "source": [
        "**Implement Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b659a6",
      "metadata": {
        "id": "63b659a6"
      },
      "source": [
        "Now, we can implement our linear regression model! Specifically, we will be implementing ridge regression, which is linear regression with L2 regularization. Given an (m x n) feature matrix $X$, an (m x 1) label vector $y$, and an (n x 1) weight vector $w$, the hypothesis function for linear regression is:\n",
        "\n",
        "$$\n",
        "y = X w\n",
        "$$\n",
        "\n",
        "Note that we can omit the bias term here because we have included a column of ones in our $X$ matrix, so the bias term is learned implicitly as a part of $w$. This will make our implementation easier.\n",
        "\n",
        "Our objective in linear regression is to learn the weights $w$ which best fit the data. This notion can be formalized as finding the optimal $w$ which minimizes the following loss function:\n",
        "\n",
        "$$\n",
        "\\min_{w} \\| X w - y \\|^2_2 + \\alpha \\| w \\|^2_2 \\\\\n",
        "$$\n",
        "\n",
        "This is the ridge regression loss function. The $\\| X w - y \\|^2_2$ term penalizes predictions $Xw$ which are not close to the label $y$. And the $\\alpha \\| w \\|^2_2$ penalizes large weight values, to favor a simpler, more generalizable model. The $\\alpha$ hyperparameter, known as the regularization parameter, is used to tune the complexity of the model - a higher $\\alpha$ results in smaller weights and lower complexity, and vice versa. Setting $\\alpha = 0$ gives us vanilla linear regression.\n",
        "\n",
        "Conveniently, ridge regression has a closed-form solution which gives us the optimal $w$ without having to do iterative methods such as gradient descent. The closed-form solution, known as the Normal Equations, is given by:\n",
        "\n",
        "$$\n",
        "w = (X^T X + \\alpha I)^{-1} X^T y\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e132b4",
      "metadata": {
        "id": "a7e132b4"
      },
      "source": [
        "**1.10. Implement a `LinearRegression` class with two methods: `train` and `predict`. You may NOT use sklearn for this implementation. You may, however, use `np.linalg.solve` to find the closed-form solution. It is highly recommended that you vectorize your code.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8cee4a",
      "metadata": {
        "id": "2e8cee4a"
      },
      "outputs": [],
      "source": [
        "class LinearRegression():\n",
        "    '''\n",
        "    Linear regression model with L2-regularization (i.e. ridge regression).\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    alpha: regularization parameter\n",
        "    w: (n x 1) weight vector\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, alpha=0):\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "\n",
        "    def train(self, X, y):\n",
        "        '''Trains model using ridge regression closed-form solution \n",
        "        (sets w to its optimal value).\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        y: (m x 1) label vector\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        '''\n",
        "        ### Your code here\n",
        "        \n",
        "    def predict(self, X):\n",
        "        '''Predicts on X using trained model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: (m x 1) prediction vector\n",
        "        '''\n",
        "        ### Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48a741e",
      "metadata": {
        "id": "c48a741e"
      },
      "source": [
        "**Train, Evaluate, and Interpret Linear Regression Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ae0161",
      "metadata": {
        "id": "18ae0161"
      },
      "source": [
        "**1.11. A) Train a linear regression model ($\\alpha = 0$) on the auto MPG training data. Make predictions and report the mean-squared error (MSE) on the training, validation, and test sets. Report the first 5 predictions on the test set, along with the actual labels.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252db724",
      "metadata": {
        "id": "252db724"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fad4d6f",
      "metadata": {
        "id": "9fad4d6f"
      },
      "source": [
        "**B) As a baseline model, use the mean of the training labels (auto_mpg_y_train) as the prediction for all instances. Report the mean-squared error (MSE) on the training, validation, and test sets using this baseline. This is a common baseline used in regression problems and tells you if your model is any good. Your linear regression MSEs should be much lower than these baseline MSEs.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d948c5",
      "metadata": {
        "id": "74d948c5"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726f5bb6",
      "metadata": {
        "id": "726f5bb6"
      },
      "source": [
        "**1.12. Interpret your model trained on the auto MPG dataset using a bar chart of the model weights. Make sure to label the bars (x-axis) and don't forget the bias term! Use lecture 3, slide 15 as a reference. According to your model, which features are the greatest contributors to the selling price**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fccabaa",
      "metadata": {
        "id": "9fccabaa"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12c284a",
      "metadata": {
        "id": "c12c284a"
      },
      "source": [
        "**Tune Regularization Parameter $\\alpha$**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a3e73e6",
      "metadata": {
        "id": "2a3e73e6"
      },
      "source": [
        "**Now, let's do ridge regression and tune the $\\alpha$ regularization parameter on the auto MPG dataset.**\n",
        "\n",
        "**1.13. Sweep out values for $\\alpha$ using `alphas = np.logspace(-2, 1, 10)`. Perform a grid search over these $\\alpha$ values, recording the training and validation MSEs for each $\\alpha$. A simple grid search is fine, no need for k-fold cross validation. Plot the training and validation MSEs as a function of $\\alpha$ on a single figure. Make sure to label the axes and the training and validation MSE curves. Use a log scale for the x-axis.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97cb6245",
      "metadata": {
        "id": "97cb6245"
      },
      "outputs": [],
      "source": [
        "### Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc61366",
      "metadata": {
        "id": "bcc61366"
      },
      "source": [
        "**Explain your plot above. How do training and validation MSE behave with decreasing model complexity (increasing $\\alpha$)?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "170c66bd",
      "metadata": {
        "id": "170c66bd"
      },
      "outputs": [],
      "source": [
        "### Your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf60747",
      "metadata": {
        "id": "faf60747"
      },
      "source": [
        "**1.14. Using the $\\alpha$ which gave the best validation MSE above, train a model on the training set. Report the value of $\\alpha$ and its training, validation, and test MSE. This is the final tuned model which you would deploy in production.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec8f5a1",
      "metadata": {
        "id": "4ec8f5a1"
      },
      "outputs": [],
      "source": [
        "### Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d5e341",
      "metadata": {
        "id": "05d5e341"
      },
      "source": [
        "# **Part 2: Logistic Regression**\n",
        "\n",
        "**Gender Recognition by Voice and Speech Analysis**\n",
        "\n",
        "**This dataset is used to identify a voice as male or female, based upon acoustic properties of the voice and speech.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f585b079",
      "metadata": {
        "id": "f585b079"
      },
      "outputs": [],
      "source": [
        "voice_df = pd.read_csv(\"voice-classification.csv\")\n",
        "voice_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b513a2",
      "metadata": {
        "id": "f0b513a2"
      },
      "source": [
        "**Data - Checking Rows & Columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7505761",
      "metadata": {
        "id": "c7505761"
      },
      "outputs": [],
      "source": [
        "#Number of Rows & Columns\n",
        "print(voice_df.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305b947d",
      "metadata": {
        "id": "305b947d"
      },
      "source": [
        "**2.1 What is the probability of observing different  categories in the Label feature of the dataset?**\n",
        "\n",
        "This is mainly to check class imbalance in the dataset, and to apply different techniques to balance the dataset, which we will learn later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fab9321",
      "metadata": {
        "id": "5fab9321"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8ae809",
      "metadata": {
        "id": "6b8ae809"
      },
      "source": [
        "**2.2 Plot the relationships between the label and the 20 numerical features using a small multiple of box plots. Make sure to label the axes. What useful information do this plot provide?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9b532f",
      "metadata": {
        "id": "da9b532f"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cdbd8c",
      "metadata": {
        "id": "c0cdbd8c"
      },
      "source": [
        "**2.3 Plot the correlation matrix, and check if there is high correlation between the given numerical features (Threshold >=0.9). If yes, drop those highly correlated features from the dataframe. Why is necessary to drop those columns before proceeding further?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fdcb929",
      "metadata": {
        "id": "0fdcb929"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1eb8c4",
      "metadata": {
        "id": "6e1eb8c4"
      },
      "source": [
        "**Separating Features & Y variable from the processed dataset**\n",
        "\n",
        "**Please note to replace the dataframe below with the new dataframe created after removing highly correlated features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0697d57b",
      "metadata": {
        "id": "0697d57b"
      },
      "outputs": [],
      "source": [
        "# Split data into features and labels\n",
        "voice_X = voice_df1.drop(columns=['label']) #replace \"voice_df1\" with your dataframe from 2.3 to make sure the code runs\n",
        "voice_y = voice_df1['label']\n",
        "print(voice_X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42edec62",
      "metadata": {
        "id": "42edec62"
      },
      "source": [
        "**2.4 Apply the following pre-processing steps:**\n",
        "\n",
        "1) Use OrdinalEncoding to encode the label in the dataset (male & female)\n",
        "\n",
        "2) Convert the label from a Pandas series to a Numpy (m x 1) vector. If you don't do this, it may cause problems when implementing the logistic regression model.\n",
        "\n",
        "3)Split the dataset into training (60%), validation (20%), and test (20%) sets.\n",
        "\n",
        "4) Standardize the columns in the feature matrices. To avoid information leakage, learn the standardization parameters from training, and then apply training, validation and test dataset.\n",
        "\n",
        "5) Add a column of ones to the feature matrices of train, validation and test dataset. This is a common trick so that we can learn a coefficient for the bias term of a linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99b06f8",
      "metadata": {
        "id": "a99b06f8"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff63db53",
      "metadata": {
        "id": "ff63db53"
      },
      "source": [
        "**2.5 Implement Logistic Regression**\n",
        "\n",
        "We will now implement logistic regression with L2 regularization. Given an (m x n) feature matrix $X$, an (m x 1) label vector $y$, and an (n x 1) weight vector $w$, the hypothesis function for logistic regression is:\n",
        "\n",
        "$$\n",
        "y = \\sigma(X w)\n",
        "$$\n",
        "\n",
        "where $\\sigma(x) = \\frac{1}{1 + e^{-x}}$, i.e. the sigmoid function. This function scales the prediction to be a probability between 0 and 1, and can then be thresholded to get a discrete class prediction.\n",
        "\n",
        "Just as with linear regression, our objective in logistic regression is to learn the weights $ùë§$ which best fit the data. For L2-regularized logistic regression, we find an optimal $w$ to minimize the following loss function:\n",
        "\n",
        "$$\n",
        "\\min_{w} \\ -y^T \\ \\text{log}(\\sigma(Xw)) \\ - \\  (\\mathbf{1} - y)^T \\ \\text{log}(\\mathbf{1} - \\sigma(Xw)) \\ + \\ \\alpha \\| w \\|^2_2 \\\\\n",
        "$$\n",
        "\n",
        "Unlike linear regression, however, logistic regression has no closed-form solution for the optimal $w$. So, we will use gradient descent to find the optimal $w$. The (n x 1) gradient vector $g$ for the loss function above is:\n",
        "\n",
        "$$\n",
        "g = X^T \\Big(\\sigma(Xw) - y\\Big) + 2 \\alpha w\n",
        "$$\n",
        "\n",
        "Below is pseudocode for gradient descent to find the optimal $w$. You should first initialize $w$ (e.g. to a (n x 1) zero vector). Then, for some number of epochs $t$, you should update $w$ with $w - \\eta g $, where $\\eta$ is the learning rate and $g$ is the gradient. You can learn more about gradient descent [here](https://www.coursera.org/lecture/machine-learning/gradient-descent-8SpIM).\n",
        "\n",
        "> $w = \\mathbf{0}$\n",
        "> \n",
        "> $\\text{for } i = 1, 2, ..., t$\n",
        ">\n",
        "> $\\quad \\quad w = w - \\eta g $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809b33ad",
      "metadata": {
        "id": "809b33ad"
      },
      "source": [
        "Implement a LogisticRegression class with five methods: train, predict, calculate_loss, calculate_gradient, and calculate_sigmoid. **You may NOT use sklearn for this implementation. It is highly recommended that you vectorize your code.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cdcee7c",
      "metadata": {
        "id": "0cdcee7c"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression():\n",
        "    '''\n",
        "    Logistic regression model with L2 regularization.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    alpha: regularization parameter\n",
        "    t: number of epochs to run gradient descent\n",
        "    eta: learning rate for gradient descent\n",
        "    w: (n x 1) weight vector\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, alpha, t, eta):\n",
        "        self.alpha = alpha\n",
        "        self.t = t\n",
        "        self.eta = eta\n",
        "        self.w = None\n",
        "\n",
        "    def train(self, X, y):\n",
        "        '''Trains logistic regression model using gradient descent \n",
        "        (sets w to its optimal value).\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        y: (m x 1) label vector\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        losses: (t x 1) vector of losses at each epoch of gradient descent\n",
        "        '''\n",
        "        ### Your code here\n",
        "        \n",
        "    def predict(self, X):\n",
        "        '''Predicts on X using trained model. Make sure to threshold \n",
        "        the predicted probability to return a 0 or 1 prediction.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: (m x 1) 0/1 prediction vector\n",
        "        '''\n",
        "        ### Your code here\n",
        "    \n",
        "    def calculate_loss(self, X, y):\n",
        "        '''Calculates the logistic regression loss using X, y, w, \n",
        "        and alpha. Useful as a helper function for train().\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        y: (m x 1) label vector\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        loss: (scalar) logistic regression loss\n",
        "        '''\n",
        "        ### Your code here\n",
        "    \n",
        "    def calculate_gradient(self, X, y):\n",
        "        '''Calculates the gradient of the logistic regression loss \n",
        "        using X, y, w, and alpha. Useful as a helper function \n",
        "        for train().\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (m x n) feature matrix\n",
        "        y: (m x 1) label vector\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        gradient: (n x 1) gradient vector for logistic regression loss\n",
        "        '''\n",
        "        ### Your code here\n",
        "    \n",
        "    def calculate_sigmoid(self, x):\n",
        "        '''Calculates the sigmoid function on each element in vector x. \n",
        "        Useful as a helper function for predict(), calculate_loss(), \n",
        "        and calculate_gradient().\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x: (m x 1) vector\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        sigmoid_x: (m x 1) vector of sigmoid on each element in x\n",
        "        '''\n",
        "        ### Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f34a6f",
      "metadata": {
        "id": "d6f34a6f"
      },
      "source": [
        "**2.6 Plot Loss over Epoch and Search the space randomly to find best hyperparameters.**\n",
        "\n",
        "A: Using your implementation above, train a logistic regression model **(alpha=0, t=100, eta=1e-3)** on the voice recognition training data. Plot the training loss over epochs. Make sure to label your axes. You should see the loss decreasing and start to converge. \n",
        "\n",
        "B: Using **alpha between (0,1), eta between(0, 0.001) and t between (0, 100)**, find the best hyperparameters for LogisticRegression. You can randomly search the space 20 times to find the best hyperparameters.\n",
        "\n",
        "C. Compare accuracy on the test dataset for both the scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c785b3bb",
      "metadata": {
        "id": "c785b3bb"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f188a581",
      "metadata": {
        "id": "f188a581"
      },
      "source": [
        "**2.7 Feature Importance**\n",
        "\n",
        "Interpret your trained model using a bar chart of the model weights. Make sure to label the bars (x-axis) and don't forget the bias term! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b31e859",
      "metadata": {
        "id": "8b31e859"
      },
      "outputs": [],
      "source": [
        "#code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3307a991",
      "metadata": {
        "id": "3307a991"
      },
      "source": [
        "\n",
        "# **Part 3: Support Vector Machines - with the same Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Dual SVM**\n",
        "\n",
        "A) Train a dual SVM (with default parameters) for both kernel=‚Äúlinear‚Äù and kernel=‚Äúrbf‚Äù) on the Voice Recognition training data.\n",
        "\n",
        "B) Make predictions and report the accuracy on the training, validation, and test sets. Which kernel gave better accuracy on test dataset and why do you think that was better?\n",
        "\n",
        "C) Please report the support vectors in both the cases and what do you observe? Explain\n"
      ],
      "metadata": {
        "id": "_cdNyA8r8eNX"
      },
      "id": "_cdNyA8r8eNX"
    },
    {
      "cell_type": "code",
      "source": [
        "#code here"
      ],
      "metadata": {
        "id": "zq6AK8Jt8gWN"
      },
      "id": "zq6AK8Jt8gWN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Using Kernel ‚Äúrbf‚Äù, tune the hyperparameter ‚ÄúC‚Äù using the Grid Search & k-fold cross validation. You may take k=5 and assume values in grid between 1 to 100 with interval range of your choice.**"
      ],
      "metadata": {
        "id": "P2h1rkaQ8rOr"
      },
      "id": "P2h1rkaQ8rOr"
    },
    {
      "cell_type": "code",
      "source": [
        "#code here"
      ],
      "metadata": {
        "id": "QVoqZtQ38wPN"
      },
      "id": "QVoqZtQ38wPN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Assignment_1_Spring_22_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "71ebca87",
        "1e3b7ca8",
        "c48a741e",
        "c12c284a"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}